
Problema?
    Principais razoÌƒes pelas quais algoritmos aÌ€s vezes naÌƒo apresentam boa performance preditiva:
* ExtrapolacÌ§aÌƒo inadequada dos resultados.
* PreÌ-processamento inadequado dos dados.
* Sobreajuste (mais importante).
* ValidacÌ§aÌƒo inadequada da qualidade dos algoritmos.
EXTRAPOLAÃ‡ÃƒO INADEQUADA
â€¢ Desenvolver os algoritmos para uma populacÌ§aÌƒo e esperar que funcionam corretamente para outra diferente.
â€¢ Importar algoritmos dos EUA/Europa: nossas caracteriÌsticas geneÌticas e socioeconoÌ‚micas saÌƒo muito diferentes.
â€¢ ExtrapolacÌ§aÌƒo para periÌodos diferentes (cuidado com doencÌ§as sazonais).
PRÃ‰-PROCESSAMENTO INADEQUADO
TeÌcnicas:
â€¢ SelecÌ§aÌƒo das variaÌveis.
â€¢ Vazamento de dados.
â€¢ PadronizacÌ§aÌƒo.
â€¢ ReducÌ§aÌƒo de dimensaÌƒo.
â€¢ Colinearidade.
â€¢ Valores missing.
â€¢ One-hot encoding.
SeleÃ§Ã£o das variÃ¡veis
â€¢ PreÌ-selecionar variaÌveis que sejam preditoras plausiÌveis (bom senso do pesquisador).
â€¢ CoincideÌ‚ncias acontecem em anaÌlises de big data e pode ser que o algoritmo deÌ‚ muita importaÌ‚ncia para associacÌ§oÌƒes espuÌrias.
> Tylervigen.com (variÃ¡veis com variÃ¡veis que nao fazem sentido)

Vazamento de dados
â€œdata leakageâ€.
- Acontece quando os dados de treino apresentam informacÌ§aÌƒo escondida que faz com que o modelo aprenda padroÌƒes que naÌƒo saÌƒo do seu interesse.
- Uma variaÌvel preditora tem escondida o resultado certo: NaÌƒo eÌ a variaÌvel que estaÌ predizendo o desfecho, mas o desfecho que estaÌ predizendo ela. 
Exemplo: Incluir o nuÌmero identificador do paciente como variaÌvel preditora
(Se pacientes de hospital especializado em caÌ‚ncer tiverem nuÌmeros semelhantes. Se o objetivo for predizer caÌ‚ncer, algoritmo iraÌ dar maior probabilidade a esses pacientes.
Esse algoritmo aprendeu algo interessante para o sistema de sauÌde?)
Motivo pelo qual os dados e os algoritmos de machine learning precisam ser abertos.
Watson prediz bem: mas eÌ informacÌ§aÌƒo uÌtil ou vazamento?

PadronizaÃ§Ã£o 
- A escala das variaÌveis pode afetar muito a qualidade das predicÌ§oÌƒes.
- Alguns algoritmos daraÌƒo prefereÌ‚ncia para utilizar variaÌveis com valores muito alto.
Passar para score Z:
ğ‘§ğ‘– = ğ‘¥ğ‘– âˆ’ ğœ‡ 
          ğœ
Zi = Xi-mÃ©dia(presente)/
          desvio padrÃ£o
MÃ©dia = 0, DP = 1

ReduÃ§Ã£o de dimensÃ£o 
Retirar variÃ¡veis que nao acha importante, se tiverem muitas importantes, reduzir em variÃ¡veis que capturam o mÃ¡ximo possÃ­vel.
Pq? Quanto maior a dimensaÌƒo dos dados (nuÌmero de variaÌveis) maior o risco de o algoritmo encontrar e utilizar associacÌ§oÌƒes espuÌrias.
Como?
PCA (aprendizado nao supervisionado)
O objetivo eÌ encontrar combinacÌ§oÌƒes lineares das variaÌveis preditoras que incluam a maior quantidade possiÌvel da variaÌ‚ncia original.
O primeiro componente principal iraÌ preservar a maior combinacÌ§aÌƒo linear possiÌvel dos dados, o segundo a maior combinacÌ§aÌƒo linear possiÌvel naÌƒo correlacionada com o primeiro componente, etc.

Colinearidade
Uma das razoÌƒes pela qual a ACP eÌ taÌƒo utilizada, eÌ o fato de que cria componentes principais naÌƒo correlacionados.
> Na praÌtica, alguns algoritmos conseguem melhor performance preditiva com variaÌveis com baixa correlacÌ§aÌƒo.
Uma outra forma de diminuir a presencÌ§a de variaÌveis com alta correlacÌ§aÌƒo eÌ excluiÌ-las.
- VariaÌveis colineares trazem informacÌ§aÌƒo redundante (tempo perdido).
- AleÌm disso, aumentam a instabilidade dos modelos.
- Estabelecer um limite de correlacÌ§aÌƒo com alguma outra
variaÌvel (0,75 a 0,90).

Valores Missing
Na prediÃ§Ã£o, gostamos de missing pelo fato de ter informaÃ§Ã£o preditoraâ€¦
Motivo sistemaÌtico -> INFORMACÌ§AÌƒO PREDITIVA.
Grande diferencÌ§a em relacÌ§aÌƒo a estudos de infereÌ‚ncia, em que valores missing devem ser evitados.
NaÌƒo conseguiu responder a uma pergunta sobre o seu passado -> INFORMACÌ§AÌƒO PREDITIVA.
Pode ajudar na predicÌ§aÌƒo de problemas cognitivos graves no futuro.
>Em variaÌveis categoÌricas adicionar uma categoria para missing. 
> ImputacÌ§aÌƒo com machine learning ()
Ao predizer qual seria esse valor se ele existisseâ€¦
One-hot encoding 
Quando tem variÃ¡veis categÃ³ricas, e vÃ¡rias dentro destasâ€¦
Mesmo que avise a ele, acaba dando problema!!
Transformar categoria em variÃ¡veis (0,1,2)
Alguns algoritmos teÌ‚m dificuldade em entender variaÌveis que teÌ‚m mais do que uma categoria.
Acham que eÌ uma variaÌvel contiÌnua (0, 1, 2, 3â€¦) â€” poreÌm naÌƒo teÌ‚m significado contiÌnuo.
A solucÌ§aÌƒo eÌ transformar todas as categorias em uma variaÌvel diferente de valores 0 e 1 (one-hot encoding).
VariaÌvel com n categorias >â€” criadas n variaÌveis.
Pode trazer problemas em alguns modelos, como na regressaÌƒo linear.
SolucÌ§aÌƒo: criar Dummies: n-1.
n-1 variaÌveis (deixar a mais frequente como categoria de refereÌ‚ncia). 
Problema: se usar interceptron, pode fazer matriz nao ficar inversÃ­vel

SOBREAJUSTE*
Maior problema de Machine Learning
NÃ£o funciona bem no futuro pq os algorÃ­tmos decoraram os dados
Modelos muito complexos:
- Funcionam perfeitamente para a amostra em questaÌƒo, mas naÌƒo muito bem para amostras futuras.
- Dados influenciados por fatores aleatoÌrios e erros de medida.

Como controlar? Fazer passar de Overfit -> Right -> Underfit
CorreÃ§Ã£o humana!!!
Tradeoff entre vieÌs e variaÌ‚ncia:
- VieÌs: erro gerado pelo uso de modelos para dados reais.
- VariaÌ‚ncia: quando pequenas mudancÌ§as nos dados levam a uma mudancÌ§a muito grande nos paraÌ‚metros.
Modelo com alta variaÌ‚ncia e pouco vieÌs
- 2 variaÌveis: linha que passa exatamente por todos os pontos.
- Se ajusta perfeitamente aos dados atuais, mas naÌƒo aos futuros.
Modelo com baixa variaÌ‚ncia e alto vieÌs
- 2 variaÌveis: linha reta para associacÌ§aÌƒo naÌƒo-linear.
- Modelo simples, com baixo poder preditivo.
Como ve se ta com sobreajuste? Olha para o futuro.
Avaliar a performance preditiva do modelo em dados que naÌƒo foram utilizados para definir o modelo.
- Se a performance preditiva cair muito com os novos dados: o modelo tem sobreajuste.
- EÌ muito faÌcil ter boa predicÌ§aÌƒo nos dados que foram utilizados para definir o modelo: eÌ soÌ tornar o modelo muito complexo.
SoluÃ§Ãµes??
Utilizar dados do periÌodo seguinte.
- Exemplo: treinar o modelo em dados de 2016 e avaliar sua performance em dados de 2017.
- Problema: na maioria das vezes, os dados saÌƒo coletados num mesmo periÌodo.
Separar os dados aleatoriamente em treino e teste.
Dados de â€œtreinoâ€ (70-80%) saÌƒo usados para definir o modelo e dados de â€œtesteâ€ (20-30%) saÌƒo usados uma uÌnica vez para analisar a performance preditiva final dos modelos.
Usar uma Ãºnica vez os dados de teste (testar qualidade, dados futuros).
Usar os dados de treino!! (senao volta o sobreajuste decorando o teste)
Para anaÌlises em que o desfecho a ser predito eÌ uma categoria:
- Amostragem estratificada entre treino e teste.
- Manter mesma proporcÌ§aÌƒo do desfecho de interesse nos dois grupos.
Alguns algoritmos na praÌtica conseguem melhor performance com distribuicÌ§aÌƒo igual entre as categorias: desfecho binaÌrio com 50% cada.
SolucÌ§oÌƒes:
â€¢ Down-sampling: selecionar amostra da classe mais frequente ateÌ se igualar aÌ€ menos frequente.
â€¢ Up-sampling: amostragem com reposicÌ§aÌƒo da classe menos frequente ateÌ se igualar aÌ€ mais frequente.
â€¢ SMOTE: combinacÌ§aÌƒo de down e up-sampling.
Definir o modelo: Ã© saber os parÃ¢metros que o algoritmos sozinho aprende (ex: os deltas, estruturas das Ã¡vores), e os hiperparÃ¢metros (definidos pelo pesquisador), em geral regularizados, forÃ§ando a ser mais simples para evitar sobreajuste.
Parecido com â€œpodar a Ã¡rvoreâ€, nao deixando que ela fique muito longa.

VALIDAÃ‡ÃƒO INADEQUADA
faz validaÃ§Ã£o cruzada
Treina em 9, testa em 1
Mesmos hiperparÃ¢metros, treina aleatorio em 9, e em 1
